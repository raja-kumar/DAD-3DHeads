{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "import os\n",
    "from pytorch_toolbelt.utils import read_rgb_image\n",
    "from predictor import FaceMeshPredictor\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from model_training.utils import load_indices_from_npy\n",
    "from utils import get_relative_path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dad_net_custom_points(image_path, indices_file):\n",
    "\n",
    "    # pass a numpy indices to get those points \n",
    "    \n",
    "    image = read_rgb_image(image_path)\n",
    "    predictor = FaceMeshPredictor.dad_3dnet()\n",
    "    predictions = predictor(image)\n",
    "    projected_vertices = predictions[\"projected_vertices\"].squeeze().numpy().astype(int) # projected vertices (total of 5023)\n",
    "    #print(projected_vertices.shape)\n",
    "    indices = np.load(indices_file)\n",
    "    points = []\n",
    "    points.extend(np.take(projected_vertices, indices, axis=0))\n",
    "\n",
    "    points = np.array(points)\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dad_net_dir(image_dir, output_dir, indices_file):\n",
    "    images = os.listdir(image_dir)\n",
    "\n",
    "    for image in images:\n",
    "        filename = image.split('.')[0]\n",
    "        curr_image = os.path.join(image_dir, image)\n",
    "        output_path = os.path.join(output_dir, filename+'.npy')\n",
    "        curr_points = run_dad_net_custom_points(curr_image, indices_file)\n",
    "        np.save(output_path, curr_points)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajakumar/miniforge3/envs/dad_3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1051: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return forward_call(*input, **kwargs)\n",
      "/Users/rajakumar/miniforge3/envs/dad_3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1051: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return forward_call(*input, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "image_dir = '../my_code/2D_lmk_ideas/dense_2d/sample_data/images/'\n",
    "output_dir = '../my_code/2D_lmk_ideas/dense_2d/sample_data/dadnet_2d/'\n",
    "indices_file = \"./model_training/model/static/face_keypoints/ids1.npy\"\n",
    "\n",
    "run_dad_net_dir(image_dir, output_dir, indices_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dad_3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:16) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5796df81dbfa9d73d5f5430114a8c6003918df0f1ffc6a75c58a987af26b37fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
